{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitbaseconda6a1770027b924823bf65f396110ad90f",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "bc4fbd6e1bea1fda9411923f753f92d3282c070fdbd959891bf5a78b35520a26"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "from Model import *\n",
    "from dataset import Dataset\n",
    "import numpy as np\n",
    "from Optimizer import Optimizer\n",
    "from Loss import *\n",
    "from Layer import backproplogger\n",
    "\n",
    "backproplogger.setLevel(logging.WARNING)\n",
    "\n",
    "# logger = logging.getLogger('simple_example')\n",
    "# logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_errors(yhati, yi):\n",
    "    errcount = 0\n",
    "    for yhat, y in zip(yhati, yi):\n",
    "        if (np.argmax(yhat) != np.argmax(y)):\n",
    "            errcount += 1\n",
    "    return(errcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Dataset(\"../datasets/dataset_train.csv\")\n",
    "m = Model(sizes = [8, 10, 4], activations = [\"sigmoid\", \"softmax\"], optimizer=Optimizer(learning_rate=0.001, Loss=CrossEntropyLoss()))\n",
    "test = np.genfromtxt(\"../data/trainout.csv\", delimiter=\",\")\n",
    "l = m.layers[-1]\n",
    "d.x = d.x\n",
    "d.y = d.y\n",
    "d.y[0][2] = 0\n",
    "d.y[0][0] = 1\n",
    "mask = []\n",
    "for i in range(100):\n",
    "    mask.append(i)\n",
    "ex = d.x[mask]\n",
    "ey = d.y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "l.z:\n[[-1.40 -1.70  3.56 -0.44]\n [-2.19 -1.20 -0.80  4.52]\n [-1.64 -1.62  3.91 -0.57]\n ...\n [ 4.22 -1.37 -0.60 -2.40]\n [-1.40  4.43 -1.35 -0.67]\n [-0.64  4.35 -1.18 -1.58]]\n\nl.a:\n[[ 0.01  0.01  0.97  0.02]\n [ 0.00  0.00  0.00  0.99]\n [ 0.00  0.00  0.98  0.01]\n ...\n [ 0.99  0.00  0.01  0.00]\n [ 0.00  0.99  0.00  0.01]\n [ 0.01  0.99  0.00  0.00]]\n\ny:\n[[1 0 0 0]\n [0 0 0 1]\n [0 0 1 0]\n ...\n [1 0 0 0]\n [0 1 0 0]\n [0 1 0 0]]\n\nx:\n[[ 1.00 -1.03  0.88 ...  1.04  0.36  0.21]\n [ 1.00 -1.16 -1.39 ... -0.54 -1.21  0.65]\n [ 1.00 -0.80  1.26 ...  1.86  1.02  1.32]\n ...\n [ 1.00  0.97 -0.85 ... -0.32  1.33 -1.75]\n [ 1.00  0.79  0.44 ... -1.25 -1.06  1.32]\n [ 1.00  1.25  0.82 ... -0.01 -1.48  0.10]]\n\nl.w:\n[[ 0.50 -0.40 -0.08 -0.21]\n [-0.89  1.25  1.58 -2.02]\n [ 0.39 -2.35  0.73  1.23]\n [ 1.52  0.97 -1.47 -0.81]\n [ 0.09 -1.44  1.70 -0.36]\n [ 1.20 -0.89 -0.26 -0.65]\n [-1.57  0.24  0.45  1.04]\n [-1.98  0.82 -0.14  1.33]\n [-0.29  1.55 -0.10 -0.60]\n [ 1.23  0.20 -0.13 -1.01]\n [ 0.10  0.48 -1.79  1.55]]\n\n\n30\n"
     ]
    }
   ],
   "source": [
    "# m.Optimizer.lr = 1\n",
    "x = ex\n",
    "y = ey\n",
    "for i in range(100):\n",
    "    m.fit(x, y)\n",
    "    # print(\"\\n\")\n",
    "print(f\"l.z:\\n{l.z}\\n\\nl.a:\\n{l.a}\\n\\ny:\\n{y}\\n\\nx:\\n{x}\\n\\nl.w:\\n{l.w}\\n\\n\")\n",
    "print(count_errors(l.a, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.05658387756474216"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "np.mean(np.abs(m.layers[-1].a - d.y)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.00,  0.00,  0.00, ...,  0.09,  0.00,  0.00],\n",
       "       [ 0.00,  1.00,  0.00, ...,  1.00,  0.00,  1.00],\n",
       "       [ 1.00,  0.00,  0.00, ...,  0.23,  0.00,  0.00],\n",
       "       ...,\n",
       "       [ 0.00,  1.00,  1.00, ...,  0.00,  1.00,  0.00],\n",
       "       [ 1.00,  0.00,  1.00, ...,  1.00,  1.00,  1.00],\n",
       "       [ 1.00,  0.00,  1.00, ...,  0.99,  1.00,  1.00]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "m.layers[0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.05  0.68  0.26  0.01] [1 0 0 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.54  0.00  0.46  0.00] [0 0 1 0]\n[ 0.97  0.00  0.02  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.54  0.00  0.46  0.00] [0 0 1 0]\n[ 0.87  0.00  0.13  0.00] [0 0 1 0]\n[ 0.90  0.00  0.10  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.75  0.00  0.25  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.56  0.01  0.00  0.44] [0 0 0 1]\n[ 0.90  0.00  0.10  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.93  0.00  0.07  0.00] [0 0 1 0]\n[ 0.70  0.00  0.29  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.00  0.00  0.00  1.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [0 0 1 0]\n[ 0.68  0.00  0.30  0.01] [0 0 1 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 0.82  0.00  0.17  0.02] [0 0 1 0]\n[ 0.91  0.00  0.09  0.00] [0 0 1 0]\n[ 0.75  0.00  0.25  0.00] [0 0 1 0]\n[ 0.82  0.00  0.17  0.01] [0 0 1 0]\n[ 0.01  0.01  0.98  0.00] [0 0 0 1]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.61  0.00  0.37  0.02] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.61  0.00  0.38  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.98  0.00  0.01  0.00] [0 0 1 0]\n[ 0.98  0.00  0.01  0.00] [0 0 1 0]\n[ 0.88  0.00  0.12  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.54  0.01  0.00  0.45] [0 0 0 1]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.87  0.00  0.13  0.00] [0 0 1 0]\n[ 0.90  0.00  0.10  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.00  0.03] [0 0 0 1]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.95  0.00  0.04  0.00] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.97  0.00  0.02  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.99  0.00  0.00  0.01] [0 0 0 1]\n[ 0.90  0.00  0.09  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.77  0.00  0.16  0.07] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.86  0.00  0.14  0.00] [0 0 1 0]\n[ 0.92  0.00  0.03  0.05] [0 0 1 0]\n[ 0.77  0.00  0.00  0.23] [0 0 0 1]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.90  0.00  0.09  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.95  0.00  0.04  0.01] [0 0 1 0]\n[ 0.94  0.00  0.04  0.02] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.64  0.00  0.35  0.02] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.29  0.00  0.71  0.00] [0 0 0 1]\n[ 0.93  0.00  0.05  0.02] [0 0 1 0]\n[ 0.55  0.00  0.44  0.01] [0 0 1 0]\n[ 0.89  0.00  0.10  0.01] [0 0 1 0]\n[ 0.65  0.00  0.31  0.05] [0 0 1 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 0.97  0.00  0.02  0.00] [0 0 1 0]\n[ 0.60  0.00  0.40  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.83  0.00  0.16  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.12  0.01  0.87  0.00] [1 0 0 0]\n[ 0.93  0.00  0.07  0.00] [0 0 1 0]\n[ 0.61  0.00  0.39  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.79  0.00  0.21  0.01] [0 0 1 0]\n[ 0.94  0.00  0.05  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.88  0.00  0.12  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 0.70  0.00  0.24  0.06] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.53  0.00  0.45  0.02] [0 0 1 0]\n[ 0.95  0.00  0.04  0.01] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.80  0.00  0.19  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.54  0.00  0.45  0.01] [0 0 1 0]\n[ 0.95  0.00  0.04  0.01] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.79  0.00  0.18  0.02] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.56  0.00  0.44  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.83  0.00  0.17  0.01] [0 0 1 0]\n[ 0.00  0.00  0.00  1.00] [0 0 1 0]\n[ 0.91  0.00  0.08  0.01] [0 0 1 0]\n[ 0.96  0.00  0.03  0.00] [0 0 1 0]\n[ 0.73  0.00  0.27  0.00] [0 0 1 0]\n[ 0.77  0.00  0.22  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.74  0.00  0.26  0.00] [0 0 1 0]\n[ 0.87  0.00  0.00  0.12] [0 0 0 1]\n[ 0.98  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.27  0.29  0.44  0.00] [1 0 0 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.71  0.00  0.28  0.00] [0 0 1 0]\n[ 0.66  0.00  0.33  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.65  0.00  0.33  0.02] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.76  0.00  0.23  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.90  0.00  0.10  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.68  0.00  0.29  0.03] [0 0 1 0]\n[ 0.98  0.00  0.01  0.00] [0 0 1 0]\n[ 0.96  0.00  0.00  0.04] [0 0 0 1]\n[ 0.90  0.00  0.10  0.00] [0 1 0 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.63  0.00  0.37  0.00] [0 0 1 0]\n[ 0.92  0.00  0.08  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [1 0 0 0]\n[ 0.00  1.00  0.00  0.00] [0 0 0 1]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.70  0.00  0.24  0.06] [0 0 1 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.51  0.00  0.48  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.58  0.01  0.00  0.41] [0 0 0 1]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.58  0.00  0.40  0.01] [0 0 1 0]\n[ 0.01  0.92  0.05  0.02] [1 0 0 0]\n[ 0.68  0.00  0.31  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.83  0.00  0.15  0.02] [0 0 1 0]\n[ 0.97  0.00  0.02  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [1 0 0 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.00  0.00  0.00  1.00] [0 1 0 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.79  0.00  0.21  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.65  0.00  0.34  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.94  0.00  0.05  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.76  0.00  0.24  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.65  0.00  0.35  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.07  0.54  0.39  0.00] [1 0 0 0]\n[ 0.83  0.00  0.17  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [0 0 0 1]\n[ 0.91  0.00  0.08  0.00] [0 0 1 0]\n[ 0.98  0.00  0.00  0.02] [0 0 0 1]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 1 0 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 0.68  0.00  0.31  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.75  0.00  0.23  0.02] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.77  0.01  0.22  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.97  0.00  0.02  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 1 0 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.92  0.00  0.08  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 0.94  0.00  0.06  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.03  0.01] [0 0 1 0]\n[ 0.96  0.00  0.03  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.65  0.00  0.34  0.01] [0 0 1 0]\n[ 0.38  0.00  0.60  0.02] [0 0 0 1]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.69  0.00  0.30  0.00] [0 0 1 0]\n[ 0.98  0.00  0.01  0.00] [0 0 1 0]\n[ 0.61  0.00  0.39  0.00] [0 0 1 0]\n[ 0.29  0.02  0.39  0.31] [1 0 0 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.98  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.98  0.00  0.02  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.92  0.00  0.08  0.00] [0 0 1 0]\n[ 0.58  0.00  0.41  0.00] [0 0 1 0]\n[ 0.75  0.00  0.22  0.03] [0 0 1 0]\n[ 0.92  0.00  0.07  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.85  0.00  0.14  0.00] [0 0 1 0]\n[ 0.87  0.00  0.13  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.98  0.00  0.00  0.02] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.93  0.00  0.05  0.02] [0 0 1 0]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.57  0.00  0.42  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.72  0.00  0.27  0.01] [0 0 1 0]\n[ 0.09  0.04  0.87  0.00] [0 0 0 1]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.84  0.00  0.15  0.01] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [0 0 1 0]\n[ 0.00  0.00  0.99  0.00] [0 0 0 1]\n[ 0.00  1.00  0.00  0.00] [1 0 0 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.98  0.00  0.00  0.02] [0 0 0 1]\n[ 0.99  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.95  0.00  0.05  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.97  0.00  0.03  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.74  0.00  0.26  0.01] [0 0 1 0]\n[ 0.96  0.00  0.03  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.03  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [1 0 0 0]\n[ 0.95  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.91  0.00  0.08  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.91  0.00  0.04  0.05] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.10  0.24  0.66  0.01] [1 0 0 0]\n[ 0.92  0.00  0.07  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.82  0.00  0.18  0.01] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 1.00  0.00  0.00  0.00] [0 0 1 0]\n[ 0.87  0.00  0.12  0.01] [0 0 1 0]\n[ 0.99  0.00  0.01  0.00] [0 0 1 0]\n[ 0.96  0.00  0.04  0.00] [0 0 1 0]\n[ 0.00  1.00  0.00  0.00] [0 0 0 1]\n363\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "i = 0\n",
    "for x, y in zip(m.feed_forward(d.x), d.y):\n",
    "    if (np.argmax(x) != np.argmax(y)):\n",
    "        print(x, y)\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  1.00],\n",
       "       [ 0.00,  0.00,  1.00,  0.00],\n",
       "       ...,\n",
       "       [ 1.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  1.00,  0.00,  0.00],\n",
       "       [ 0.00,  1.00,  0.00,  0.00]])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "m.feed_forward(d.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n3\n2\n0\n0\n3\n0\n1\n0\n1\n1\n1\n1\n3\n2\n2\n0\n0\n2\n1\n0\n0\n2\n1\n0\n1\n3\n1\n0\n1\n1\n0\n2\n1\n0\n0\n1\n1\n3\n1\n0\n1\n0\n1\n1\n0\n0\n1\n3\n0\n0\n3\n3\n0\n0\n3\n1\n3\n1\n0\n3\n2\n1\n1\n1\n1\n1\n0\n0\n1\n2\n3\n3\n1\n2\n1\n0\n0\n1\n1\n1\n3\n3\n0\n1\n1\n1\n1\n1\n0\n0\n0\n0\n1\n1\n1\n0\n2\n3\n1\n0\n1\n0\n1\n0\n0\n3\n0\n1\n3\n3\n2\n0\n0\n0\n0\n0\n3\n1\n1\n0\n3\n0\n1\n1\n3\n1\n3\n0\n1\n3\n0\n3\n1\n2\n0\n0\n0\n1\n0\n0\n0\n0\n1\n0\n0\n3\n0\n0\n0\n0\n0\n0\n3\n3\n1\n0\n1\n2\n0\n1\n1\n1\n3\n0\n1\n1\n1\n3\n0\n2\n0\n0\n2\n1\n0\n0\n1\n0\n0\n3\n1\n0\n3\n3\n1\n1\n3\n1\n0\n3\n1\n0\n1\n3\n1\n1\n0\n0\n3\n1\n0\n0\n0\n0\n1\n0\n1\n1\n0\n1\n0\n3\n3\n2\n1\n0\n2\n0\n0\n1\n1\n0\n3\n0\n2\n1\n0\n1\n1\n1\n0\n1\n2\n1\n1\n3\n0\n1\n1\n1\n0\n1\n1\n1\n1\n0\n1\n0\n0\n0\n3\n3\n0\n1\n2\n2\n3\n0\n2\n3\n1\n0\n0\n3\n3\n3\n0\n1\n0\n0\n0\n1\n1\n0\n0\n2\n1\n1\n0\n1\n2\n1\n1\n0\n0\n0\n1\n1\n0\n0\n1\n1\n1\n0\n0\n1\n0\n0\n1\n0\n1\n3\n1\n1\n0\n3\n0\n1\n3\n2\n1\n3\n1\n0\n0\n0\n3\n3\n1\n1\n3\n3\n0\n1\n0\n0\n0\n0\n0\n3\n1\n1\n1\n0\n0\n3\n0\n0\n1\n3\n0\n0\n1\n3\n0\n3\n0\n1\n1\n0\n0\n0\n0\n1\n0\n3\n1\n0\n0\n1\n1\n0\n0\n3\n2\n3\n1\n0\n1\n0\n1\n1\n1\n1\n2\n0\n1\n3\n0\n1\n0\n3\n1\n0\n1\n0\n1\n0\n1\n1\n3\n1\n1\n0\n2\n0\n3\n0\n0\n0\n1\n3\n1\n2\n1\n0\n0\n3\n0\n3\n0\n0\n0\n1\n0\n3\n1\n3\n1\n1\n3\n1\n1\n3\n0\n1\n1\n1\n0\n0\n0\n1\n0\n1\n1\n0\n0\n3\n0\n1\n2\n2\n0\n0\n1\n1\n0\n0\n0\n1\n1\n3\n1\n3\n3\n2\n0\n1\n0\n1\n0\n0\n0\n1\n0\n0\n1\n3\n0\n0\n0\n1\n1\n1\n0\n1\n1\n0\n2\n1\n1\n0\n3\n1\n1\n0\n0\n1\n1\n0\n1\n3\n3\n1\n1\n3\n0\n0\n2\n0\n1\n1\n1\n0\n0\n3\n0\n1\n1\n0\n1\n0\n1\n1\n2\n0\n0\n0\n0\n1\n0\n3\n0\n3\n0\n0\n0\n0\n0\n2\n1\n0\n2\n0\n1\n0\n2\n3\n2\n3\n0\n2\n0\n0\n2\n0\n3\n1\n0\n1\n3\n0\n1\n1\n1\n0\n1\n1\n2\n3\n0\n0\n0\n1\n1\n1\n0\n0\n1\n1\n1\n0\n0\n1\n0\n1\n1\n0\n3\n0\n0\n1\n0\n0\n1\n0\n3\n3\n0\n0\n3\n3\n1\n0\n0\n1\n0\n0\n3\n0\n0\n3\n0\n0\n0\n0\n0\n3\n1\n0\n0\n3\n1\n0\n0\n0\n0\n0\n1\n3\n3\n0\n1\n0\n0\n1\n1\n0\n1\n0\n0\n0\n1\n0\n0\n0\n3\n2\n1\n1\n3\n3\n0\n1\n3\n1\n1\n1\n3\n3\n3\n1\n3\n0\n1\n0\n0\n0\n1\n3\n1\n3\n0\n0\n1\n3\n1\n1\n1\n0\n0\n3\n0\n1\n2\n1\n0\n0\n1\n3\n3\n0\n1\n2\n3\n3\n1\n2\n0\n0\n2\n0\n3\n0\n0\n0\n0\n2\n0\n1\n1\n2\n0\n0\n1\n1\n0\n0\n0\n0\n0\n2\n0\n3\n3\n1\n1\n2\n0\n0\n0\n3\n1\n3\n1\n3\n0\n0\n2\n0\n0\n3\n1\n3\n0\n0\n3\n1\n0\n1\n1\n1\n0\n0\n0\n0\n3\n1\n0\n1\n2\n1\n1\n0\n0\n1\n2\n1\n0\n1\n3\n0\n1\n1\n1\n0\n3\n1\n3\n0\n0\n0\n1\n0\n0\n3\n1\n3\n0\n3\n2\n0\n3\n1\n1\n0\n3\n0\n0\n2\n1\n0\n1\n0\n0\n0\n2\n0\n0\n3\n1\n0\n2\n2\n0\n3\n1\n0\n0\n3\n1\n3\n1\n0\n0\n3\n0\n0\n0\n1\n1\n3\n2\n1\n0\n1\n2\n0\n3\n0\n0\n0\n1\n1\n0\n1\n0\n0\n0\n1\n0\n3\n0\n1\n0\n1\n0\n1\n1\n0\n3\n0\n1\n3\n3\n3\n3\n0\n0\n0\n0\n0\n1\n1\n0\n3\n1\n0\n0\n3\n3\n1\n3\n1\n1\n1\n0\n0\n0\n0\n3\n1\n3\n0\n0\n3\n3\n3\n3\n3\n1\n1\n3\n0\n3\n0\n3\n1\n1\n0\n0\n1\n1\n3\n3\n1\n3\n0\n1\n0\n1\n0\n0\n0\n1\n1\n0\n0\n1\n0\n0\n3\n0\n1\n0\n0\n0\n1\n0\n3\n3\n1\n0\n0\n3\n1\n1\n0\n0\n0\n3\n0\n2\n1\n0\n1\n1\n0\n1\n1\n0\n3\n1\n1\n3\n0\n1\n1\n1\n1\n0\n0\n2\n1\n1\n1\n1\n0\n1\n1\n3\n0\n0\n0\n0\n3\n1\n0\n0\n0\n0\n2\n2\n1\n3\n2\n0\n0\n2\n3\n1\n2\n1\n0\n3\n0\n1\n1\n1\n0\n0\n0\n0\n3\n0\n1\n2\n0\n0\n1\n3\n1\n0\n0\n0\n1\n1\n0\n0\n2\n3\n2\n0\n0\n1\n0\n1\n0\n1\n3\n1\n0\n0\n3\n0\n0\n3\n1\n0\n2\n3\n0\n2\n2\n0\n1\n0\n2\n0\n3\n0\n1\n3\n0\n0\n0\n2\n0\n0\n0\n0\n1\n3\n2\n1\n1\n0\n1\n0\n1\n3\n1\n1\n3\n3\n0\n1\n1\n3\n2\n3\n3\n1\n0\n0\n1\n0\n0\n1\n0\n1\n1\n1\n1\n1\n2\n0\n0\n1\n3\n0\n2\n0\n0\n1\n1\n1\n2\n1\n1\n3\n1\n0\n1\n1\n1\n1\n3\n0\n0\n2\n3\n3\n0\n0\n3\n0\n3\n1\n3\n1\n1\n3\n0\n0\n0\n2\n2\n3\n1\n0\n3\n1\n0\n3\n0\n0\n1\n3\n3\n3\n2\n0\n0\n0\n0\n1\n3\n0\n1\n3\n0\n1\n0\n1\n0\n0\n0\n1\n0\n1\n1\n1\n0\n0\n1\n0\n1\n3\n3\n2\n1\n3\n1\n2\n0\n0\n1\n0\n3\n0\n0\n0\n0\n0\n0\n0\n1\n0\n3\n1\n1\n0\n0\n1\n0\n3\n3\n0\n1\n1\n3\n1\n1\n0\n3\n0\n0\n2\n3\n1\n3\n0\n1\n0\n0\n3\n3\n3\n0\n2\n0\n1\n1\n1\n0\n0\n1\n3\n1\n3\n1\n0\n1\n1\n0\n2\n2\n1\n1\n1\n1\n1\n3\n2\n0\n0\n0\n0\n1\n1\n1\n3\n3\n0\n3\n3\n1\n0\n1\n0\n3\n0\n1\n1\n1\n0\n1\n1\n2\n1\n2\n1\n3\n0\n1\n1\n0\n1\n0\n1\n3\n3\n0\n3\n0\n1\n2\n0\n3\n0\n1\n1\n2\n3\n1\n0\n0\n0\n0\n1\n1\n0\n1\n1\n1\n3\n3\n1\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n3\n2\n1\n0\n1\n3\n0\n1\n3\n0\n1\n3\n1\n0\n3\n3\n0\n0\n0\n1\n2\n1\n1\n0\n0\n1\n3\n0\n0\n2\n1\n1\n3\n2\n1\n0\n0\n2\n1\n3\n1\n0\n0\n0\n3\n1\n0\n1\n2\n0\n1\n1\n0\n0\n0\n0\n1\n2\n3\n0\n1\n0\n0\n1\n0\n0\n3\n3\n0\n0\n0\n0\n0\n1\n1\n0\n1\n3\n0\n0\n1\n3\n0\n0\n2\n1\n0\n1\n0\n3\n1\n1\n1\n0\n2\n3\n0\n1\n0\n0\n1\n3\n0\n1\n1\n0\n3\n1\n0\n2\n0\n1\n3\n0\n3\n0\n0\n3\n1\n2\n1\n1\n0\n0\n1\n2\n0\n0\n1\n1\n0\n1\n1\n1\n0\n3\n1\n3\n1\n0\n1\n3\n2\n2\n3\n3\n0\n1\n1\n0\n1\n1\n3\n1\n0\n0\n1\n0\n1\n0\n0\n1\n3\n1\n0\n0\n1\n0\n0\n1\n0\n1\n3\n3\n1\n1\n0\n2\n0\n0\n0\n0\n1\n2\n0\n0\n0\n2\n0\n1\n1\n1\n1\n1\n0\n1\n0\n3\n0\n0\n0\n1\n1\n0\n3\n1\n1\n0\n1\n1\n3\n1\n0\n3\n0\n3\n2\n0\n1\n2\n0\n2\n1\n2\n0\n2\n0\n2\n1\n0\n0\n0\n0\n0\n0\n1\n3\n1\n0\n0\n0\n2\n0\n0\n3\n1\n3\n0\n3\n3\n1\n3\n1\n3\n1\n2\n3\n0\n0\n1\n0\n1\n0\n1\n1\n"
     ]
    }
   ],
   "source": [
    "for x in m.feed_forward(d.x):\n",
    "    print(np.argmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DEBUG:root:y:\n",
      "[[0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n",
      "DEBUG:root:yhat:\n",
      "[[ 0.09  0.57  0.22  0.12]\n",
      " [ 0.02  0.35  0.50  0.13]\n",
      " [ 0.06  0.67  0.14  0.14]\n",
      " ...\n",
      " [ 0.27  0.21  0.38  0.15]\n",
      " [ 0.29  0.31  0.15  0.25]\n",
      " [ 0.39  0.23  0.10  0.29]]\n",
      "DEBUG:root:-y / yhat:\n",
      "[[ 0.00  0.00 -4.59  0.00]\n",
      " [ 0.00  0.00  0.00 -7.53]\n",
      " [ 0.00  0.00 -7.34  0.00]\n",
      " ...\n",
      " [-3.74  0.00  0.00  0.00]\n",
      " [ 0.00 -3.19  0.00  0.00]\n",
      " [ 0.00 -4.33  0.00  0.00]]\n"
     ]
    }
   ],
   "source": [
    "m.feed_forward(d.x)\n",
    "djda = m.Optimizer.Loss.loss_derivative(m.layers[-1].a, d.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = m.layers[-1]\n",
    "dadz = l.activation_derivative(l.z, l.a)\n",
    "# print(f\"{dadz.shape = }, {djda.shape = }\")\n",
    "# logging.debug(f\"djda:\\n {djda}\\n\")\n",
    "djdz = np.einsum( 'ik,ikj->ij', djda, dadz)\n",
    "djdz2 = l.a - d.y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00],\n",
       "       ...,\n",
       "       [ 0.00,  0.00,  0.00,  0.00],\n",
       "       [ 0.00, -0.00,  0.00,  0.00],\n",
       "       [ 0.00,  0.00,  0.00,  0.00]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.09  0.57  0.22  0.12]\n [ 0.02  0.35  0.50  0.13]\n [ 0.06  0.67  0.14  0.14]\n ...\n [ 0.27  0.21  0.38  0.15]\n [ 0.29  0.31  0.15  0.25]\n [ 0.39  0.23  0.10  0.29]]\n[[0 0 1 0]\n [0 0 0 1]\n [0 0 1 0]\n ...\n [1 0 0 0]\n [0 1 0 0]\n [0 1 0 0]]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-4.545454545454546"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "print(l.a)\n",
    "print(d.y)\n",
    "-1 / 0.22"
   ]
  }
 ]
}